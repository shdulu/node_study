// Buffer 也是 node全局属性global的属性，可以直接访问
// 为什么要有Buffer？ 早期js使用在浏览器中的（不能操作文件，不能读写）
// node中需要有读写文件的能力，这样就需要一种

// 文件读取的内容 表现形式 底层都是二进制 展现的形式不同 按照不同的编码展现给我

// Buffer 可以用来描述内存中的内容 （二进制数据 -> 16进制） http流

// 进制转换 2进制 最大是1  16进制最大的是 15

// 8个bit 1字节b  1024b -> 1k  1024k -> 1m 1024m - 1g

// 0.1+0.2 为什么不等于 0.3
// 存储的时候会被转化为2进制数据
// 如何将小数 转换成 二进制
// 0.5 在二进制中是多少  0.1

// 0.2+0.2 为啥精度没有丢失 js运算一个近似值的运算，所有的小数运算都会有类似的问题
// 计算的时候有的取得近似值就是正确的，有的是非正确的

// 什么叫base64？ 转化后的每一个字节都是小于64的
// utf8 编码中规定了一个汉字3个字节， 在gbk编码中1个汉字2个字节

console.log(Buffer.from("杜路")); // <Buffer e6 9d 9c>

console.log((0xe6).toString(2)); // 11100110
console.log((0x9d).toString(2)); // 10011101
console.log((0x9c).toString(2)); // 10011100

// 把汉字 3 * 8 的格式 传化出的每个字节 不得大于64

// 把汉字 3 * 8 的格式 改成 4*6 的格式 六位分割不够前面补00，这样最大 111111(64)
// 00111001  00101001 00110110 00011100
// 00111001  00101001  00110110  00011100 3 -> 4 比之前大了 1/3

console.log(parseInt("00111001", 2)); // 57
console.log(parseInt("00101001", 2)); // 41
console.log(parseInt("00110110", 2)); // 54
console.log(parseInt("00011100", 2)); // 28

// 57 41 54 28 编码 -> 解码

let str1 = "ABCDEFGHIJKLMNOPQRSTUVWXYZ";

str1 += str1.toLowerCase();
str1 += "0123456789+/";
console.log(`${str1[57]}${str1[41]}${str1[54]}${str1[28]}`); // 3o0b
// base64并不是加密算法 编码规则是公开的
